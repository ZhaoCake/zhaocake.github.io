---
draft: false
date: 2025-1-7
authors:
    - ZhaoCake
categories:
    - 项目分享

---

# 一个纯numpy实现的LeNet训练仓库（1）

!!! note "开源地址"
	https://github.com/ZhaoCake/cakeinfer_fnumpy

眼下有在FPGA上面跑神经网络的需求，目前见得最多且实现比较快的方案当然是使用HLS，所以就打算使用HLS来做做。HLS按照我目前只看了点基础的浅薄理解来说，就是对c/cpp中写出来的循环和函数以及数组通过HLS特定的pragma宏来优化，提高并行度。

!!! question "#pragma 是什么"
	`#pragma`并不是一个宏关键字，而是特定于编译器的预处理指令，比如用MSVC编译器的时候就经常看到的`#pragma once`。在Xilinx的HLS中也是通过一堆pragma来优化的。
	
但是由于基础不过关，我没能直接写出cpp实现的LeNet。这些困难应该说主要是出现在权重对齐网络的问题上的。应该说目前我的这个numpy写的LeNet的玩意儿都还有问题，因为它能够在训练时达到98的准确度，但是写出来的推理demo加载训练后的权重进行推理却要出问题。我正着手写出一个能够对模型输出的每一步计算都进行对比的测试方案。我估计问题还是处在预处理和后处理上，模型内的前向传播能够有什么问题呢？

# 附录：README.md